"""Module de scoring et rapport de qualit√©."""
import pandas as pd
from datetime import datetime
from pathlib import Path
import json
from typing import Optional
from .ai_helper import AIHelper
from dotenv import load_dotenv

from .config import QUALITY_THRESHOLDS, REPORTS_DIR
from .models import QualityMetrics

load_dotenv()


class QualityAnalyzer:
    """Analyse et score la qualit√© des donn√©es."""

    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.metrics: Optional[QualityMetrics] = None

    def calculate_completeness(self) -> float:
        """Calcule le score de compl√©tude (% de valeurs non-nulles)."""
        if self.df.empty:
            return 0.0

        total_cells = self.df.size
        non_null_cells = self.df.notna().sum().sum()
        return non_null_cells / total_cells

    def count_duplicates(self, id_columns: Optional[list[str]] = None) -> tuple[int, float]:
        """Compte les doublons."""
        if self.df.empty:
            return 0, 0.0

        if id_columns is None:
            # Trouver automatiquement les colonnes d'ID
            possible_ids = ['code', 'id', 'product_id', 'siret', 'uuid']
            id_columns = [col for col in possible_ids if col in self.df.columns]
            
            if not id_columns:
                id_columns = [self.df.columns[0]]  # Fallback: premi√®re colonne

        if not id_columns:
            return 0, 0.0

        # Compter les doublons
        duplicates = self.df.duplicated(subset=id_columns).sum()
        pct = (duplicates / len(self.df)) * 100 if len(self.df) > 0 else 0.0

        return duplicates, pct

    def calculate_geocoding_stats(self) -> tuple[float, float]:
        """Calcule les stats de g√©ocodage si applicable."""
        if self.df.empty or 'geocoding_score' not in self.df.columns:
            return 0.0, 0.0

        valid_geo = self.df['geocoding_score'].notna() & (self.df['geocoding_score'] >= 0.5)
        
        if len(self.df) == 0:
            return 0.0, 0.0

        success_rate = (valid_geo.sum() / len(self.df)) * 100
        
        if valid_geo.any():
            avg_score = self.df.loc[valid_geo, 'geocoding_score'].mean()
        else:
            avg_score = 0.0

        return success_rate, avg_score

    def calculate_null_counts(self) -> dict:
        """Compte les valeurs nulles par colonne."""
        if self.df.empty:
            return {}

        null_counts = self.df.isnull().sum().to_dict()
        
        # Ajouter les pourcentages
        null_pct = {}
        for col, count in null_counts.items():
            pct = (count / len(self.df)) * 100 if len(self.df) > 0 else 0.0
            null_pct[col] = {
                'count': count,
                'pct': round(pct, 2)
            }
        
        return null_pct

    def determine_quality_grade(
        self,
        completeness: float,
        duplicates_pct: float,
        geo_rate: float
    ) -> str:
        """D√©termine la note de qualit√© globale (A-F)."""
        score = 0.0

        # Compl√©tude (40 points max)
        score += min(completeness * 40, 40)

        # Doublons (30 points max)
        if duplicates_pct <= 1:
            score += 30
        elif duplicates_pct <= 5:
            score += 20
        elif duplicates_pct <= 10:
            score += 10
        # > 10: 0 points

        # G√©ocodage (30 points max) - si applicable
        if 'geocoding_score' in self.df.columns:
            score += min(geo_rate / 100 * 30, 30)
        else:
            score += 30  # Pas de p√©nalit√© si pas de g√©ocodage

        # Note finale
        if score >= 90:
            return 'A'
        elif score >= 75:
            return 'B'
        elif score >= 60:
            return 'C'
        elif score >= 40:
            return 'D'
        else:
            return 'F'
        
    def generate_ai_recommendations(self) -> str:
        """
        G√©n√®re des recommandations via l'IA.
        Si l'IA n'est pas disponible, retourne des recommandations standard.
        """
        if not self.metrics:
            self.analyze()
        
        # Cr√©er le contexte
        context = f"""
        Analyse de qualit√© d'un dataset :
        - Total enregistrements: {self.metrics.total_records}
        - Enregistrements valides: {self.metrics.valid_records}
        - Score de compl√©tude: {self.metrics.completeness_score * 100:.1f}%
        - Taux de doublons: {self.metrics.duplicates_pct:.1f}%
        - G√©ocodage r√©ussi: {self.metrics.geocoding_success_rate:.1f}%
        - Score g√©ocodage moyen: {self.metrics.avg_geocoding_score:.2f}
        - Note globale: {self.metrics.quality_grade}
        
        Valeurs manquantes par colonne:
        {json.dumps(self.metrics.null_counts, indent=2, ensure_ascii=False)}
        
        Veuillez donner 5 recommandations concr√®tes et actionnables pour am√©liorer ce dataset.
        Formatez en Markdown avec des listes √† puces.
        """
        
        # Essayer l'IA
        ai_helper = AIHelper()
        ai_response = ai_helper.get_recommendations(context)
        
        if ai_response:
            # Nettoyer la r√©ponse si n√©cessaire
            ai_response = ai_response.strip()
            if not ai_response.startswith("#"):
                ai_response = f"## ü§ñ Recommandations IA\n\n{ai_response}"
            return ai_response
        else:
            # Fallback aux recommandations standards
            return self._generate_standard_recommendations()

    # def generate_ai_recommendations(self) -> str:
    #     """
    #     G√©n√®re des recommandations via l'IA.
    #     Si l'IA n'est pas disponible, retourne des recommandations standard.
    #     """
    #     if not self.metrics:
    #         self.analyze()

    #     try:
    #         # Tenter d'importer litellm
    #         from litellm import completion
            
    #         context = f"""
    #         Analyse de qualit√© d'un dataset :
    #         - Total: {self.metrics.total_records} enregistrements
    #         - Valides: {self.metrics.valid_records} enregistrements
    #         - Compl√©tude: {self.metrics.completeness_score * 100:.1f}%
    #         - Doublons: {self.metrics.duplicates_pct:.1f}%
    #         - G√©ocodage r√©ussi: {self.metrics.geocoding_success_rate:.1f}%
    #         - Note globale: {self.metrics.quality_grade}
    #         """
            
    #         response = completion(
    #             model="gemini/gemini-2.0-flash-exp",
    #             messages=[
    #                 {
    #                     "role": "system",
    #                     "content": (
    #                         "Tu es un expert en qualit√© des donn√©es. "
    #                         "Donne des recommandations concr√®tes, actionnables et professionnelles. "
    #                         "Formate en markdown avec des listes √† puces."
    #                     )
    #                 },
    #                 {
    #                     "role": "user",
    #                     "content": (
    #                         f"{context}\n\n"
    #                         "Quelles sont tes 5 recommandations prioritaires "
    #                         "pour am√©liorer ce dataset ?"
    #                     )
    #                 }
    #             ]
    #         )
            
    #         return response.choices[0].message.content
            
    #     except Exception:
    #         # Fallback: recommandations standards
    #         return self._generate_standard_recommendations()

    def _generate_standard_recommendations(self) -> str:
        """G√©n√®re des recommandations standards sans IA."""
        if not self.metrics:
            self.analyze()

        recommendations = []
        
        # 1. Compl√©tude
        if self.metrics.completeness_score < QUALITY_THRESHOLDS['completeness_min']:
            recommendations.append(
                "**Am√©liorer la compl√©tude** : Les donn√©es contiennent trop de valeurs manquantes. "
                "Consid√©rer des sources suppl√©mentaires ou des techniques d'imputation."
            )
        
        # 2. Doublons
        if self.metrics.duplicates_pct > QUALITY_THRESHOLDS['duplicates_max_pct']:
            recommendations.append(
                "**Supprimer les doublons** : Plus de 5% des enregistrements sont des doublons. "
                "Impl√©menter une v√©rification des doublons avant l'insertion."
            )
        
        # 3. G√©ocodage
        if 'geocoding_score' in self.df.columns:
            if self.metrics.geocoding_success_rate < 50:
                recommendations.append(
                    "**Am√©liorer le g√©ocodage** : Le taux de succ√®s est faible. "
                    "Nettoyer les adresses avant g√©ocodage ou utiliser un service plus performant."
                )
        
        # 4. Colonnes avec trop de nulls
        null_counts = self.calculate_null_counts()
        for col, stats in null_counts.items():
            if stats['pct'] > 30:  # > 30% de nulls
                recommendations.append(
                    f"**Colonne '{col}'** : {stats['pct']}% de valeurs manquantes. "
                    "√âvaluer si cette colonne est n√©cessaire ou si elle peut √™tre enrichie."
                )
        
        # 5. Recommandation g√©n√©rale
        if not recommendations:
            recommendations.append(
                "**Maintenir la qualit√©** : Le dataset est de bonne qualit√©. "
                "Continuer √† surveiller les m√©triques et impl√©menter des contr√¥les automatis√©s."
            )
        
        # Formater en markdown
        markdown = "## Recommandations pour am√©liorer la qualit√© des donn√©es\n\n"
        for i, rec in enumerate(recommendations[:5], 1):
            markdown += f"{i}. {rec}\n\n"
        
        return markdown

    def analyze(self) -> QualityMetrics:
        """Effectue l'analyse compl√®te de qualit√©."""
        # Calculer les m√©triques
        completeness = self.calculate_completeness()
        duplicates, duplicates_pct = self.count_duplicates()
        geo_rate, geo_avg = self.calculate_geocoding_stats()
        null_counts = self.calculate_null_counts()
        
        # Compter les enregistrements valides
        valid_records = len(self.df) - duplicates
        
        # D√©terminer la note
        grade = self.determine_quality_grade(
            completeness,
            duplicates_pct,
            geo_rate
        )
        
        # Cr√©er l'objet QualityMetrics
        self.metrics = QualityMetrics(
            total_records=len(self.df),
            valid_records=valid_records,
            completeness_score=round(completeness, 3),
            duplicates_count=duplicates,
            duplicates_pct=round(duplicates_pct, 2),
            geocoding_success_rate=round(geo_rate, 2),
            avg_geocoding_score=round(geo_avg, 3),
            null_counts=null_counts,
            quality_grade=grade,
        )
        
        return self.metrics

    def generate_report(
        self,
        output_name: str = "quality_report",
        include_ai: bool = True
    ) -> Path:
        """
        G√©n√®re un rapport de qualit√© complet en Markdown.
        
        Args:
            output_name: Nom du fichier (sans extension)
            include_ai: Inclure les recommandations IA
        
        Returns:
            Chemin du fichier g√©n√©r√©
        """
        if not self.metrics:
            self.analyze()

        # G√©n√©rer les recommandations
        if include_ai:
            try:
                recommendations = self.generate_ai_recommendations()
            except Exception:
                recommendations = self._generate_standard_recommendations()
        else:
            recommendations = self._generate_standard_recommendations()

        # Construire le rapport
        report = f"""# üìä Rapport de Qualit√© des Donn√©es

**G√©n√©r√© le** : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Dataset** : {output_name}
**Nombre d'enregistrements** : {self.metrics.total_records}

---

## üìà M√©triques Globales

| M√©trique | Valeur | Seuil Recommand√© | Statut |
|----------|--------|------------------|--------|
| **Note globale** | **{self.metrics.quality_grade}** | A-B-C | {"‚úÖ Acceptable" if self.metrics.is_acceptable else "‚ö†Ô∏è N√©cessite attention"} |
| Enregistrements valides | {self.metrics.valid_records} | - | - |
| Score de compl√©tude | {self.metrics.completeness_score * 100:.1f}% | ‚â• 70% | {"‚úÖ" if self.metrics.completeness_score >= QUALITY_THRESHOLDS['completeness_min'] else "‚ö†Ô∏è"} |
| Taux de doublons | {self.metrics.duplicates_pct:.1f}% | ‚â§ 5% | {"‚úÖ" if self.metrics.duplicates_pct <= QUALITY_THRESHOLDS['duplicates_max_pct'] else "‚ö†Ô∏è"} |
| G√©ocodage r√©ussi | {self.metrics.geocoding_success_rate:.1f}% | ‚â• 50% | {"‚úÖ" if self.metrics.geocoding_success_rate >= 50 else "‚ö†Ô∏è"} |
| Score g√©ocodage moyen | {self.metrics.avg_geocoding_score:.2f} | ‚â• 0.5 | {"‚úÖ" if self.metrics.avg_geocoding_score >= QUALITY_THRESHOLDS['geocoding_score_min'] else "‚ö†Ô∏è"} |

---

## üìã Analyse des Valeurs Manquantes

| Colonne | Valeurs nulles | % | Priorit√© |
|---------|----------------|---|----------|
"""
        
        # Trier par pourcentage d√©croissant
        sorted_nulls = sorted(
            self.metrics.null_counts.items(),
            key=lambda x: x[1]['pct'],
            reverse=True
        )
        
        for col, stats in sorted_nulls:
            pct = stats['pct']
            priority = "üî¥ Haute" if pct > 30 else "üü° Moyenne" if pct > 10 else "üü¢ Basse"
            report += f"| {col} | {stats['count']} | {pct:.1f}% | {priority} |\n"

        report += f"""

---

## üéØ Conclusion Qualit√©

**Verdict** : {"‚úÖ **Dataset acceptable** pour l'analyse." if self.metrics.is_acceptable else "‚ö†Ô∏è **Dataset n√©cessite des corrections** avant utilisation."}

**Score final** : {self.metrics.quality_grade} (sur une √©chelle A-F)

---

{recommendations}

---

*Rapport g√©n√©r√© automatiquement par le pipeline Open Data*
*Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # Sauvegarder
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{output_name}_{timestamp}.md"
        filepath = REPORTS_DIR / filename
        
        # Assurer que le dossier existe
        REPORTS_DIR.mkdir(parents=True, exist_ok=True)
        
        # √âcrire le fichier
        filepath.write_text(report, encoding='utf-8')
        
        print(f"üìÑ Rapport sauvegard√© : {filepath}")
        print(f"   - Note qualit√©: {self.metrics.quality_grade}")
        print(f"   - Taille: {len(report.splitlines())} lignes")
        
        return filepath